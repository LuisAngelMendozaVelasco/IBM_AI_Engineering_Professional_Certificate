# Softmax Rergresstion

## Learning Objectives

- Use Lines to Classify Data.
- Utilize the Softmax function and understand its internal workings.
- Describe how the Softmax function generalizes to multiple dimensions.
- Explain the utilization of the argmax function.
- Use Softmax in PyTorch to perform classifications by specifying the loss criteria as cross entropy loss.
- Create a custom module for Softmax using the nn.module package in PyTorch.
- Use a Softmax classifier to create a model for performing classifications.

## 6.1 Softmax Prediction

- [Video - 6.1 Softmax](https://www.coursera.org/learn/deep-neural-networks-with-pytorch/lecture/udAw5/6-1-softmax)

## 6.2 Softmax Function

- [Video - 6.2 Softmax Function:Using Lines to Classify Data](https://www.coursera.org/learn/deep-neural-networks-with-pytorch/lecture/YhCw7/6-2-softmax-function-using-lines-to-classify-data)

## 6.3 Softmax PyTorch

- [Video - Softmax PyTorch](https://www.coursera.org/learn/deep-neural-networks-with-pytorch/lecture/ySzGY/softmax-pytorch)

- [Lab - Softmax Classifier 1](./Labs/5.4softmax_in_one_dimension_v2.ipynb)

- [Lab - Softmax Classifier 2](./Labs/6.2lab_predicting%20_MNIST_using_Softmax_v2.ipynb)

---

# Shallow Neural Networks

## Learning Objectives

- Create a Neural Network with One Hidden Layer using nn.Module.
- Create a Neural Network with One Hidden Layer using nn.Sequential.
- Train the Neural Network model.
- Explain how adding more neurons in the hidden layer can improve a model.
- Construct Networks with Multiple Dimensional input in PyTorch.
- Explain what Overfitting and Underfitting are.
- Implement Multi-Class Neural Networks in PyTorch.
- Describe what back propagation and the vanishing gradient is.
- Implement Sigmoid, Tanh and Relu activation functions in Pytorch.

## 7.1 Neural Networks in One Dimension

- [Video - What's a Neural Network](https://www.coursera.org/learn/deep-neural-networks-with-pytorch/lecture/Vpm6V/whats-a-neural-network)

- [Lab - Neural Networks in One Dimension](./Labs/7.1_simple1hiddenlayer.ipynb)

## 7.2 Neural Networks More Hidden Neurons

- [Video - More Hidden Neurons](https://www.coursera.org/learn/deep-neural-networks-with-pytorch/lecture/8GOM9/more-hidden-neurons)

- [Lab - More Hidden Neurons](./Labs/7.2multiple_neurons.ipynb)

## 7.3 Neural Networks with Multiple Dimensional Input

- [Video - Neural Networks with Multiple Dimensional Input](https://www.coursera.org/learn/deep-neural-networks-with-pytorch/lecture/iTPsF/neural-networks-with-multiple-dimensional-input)

- [Lab - Multidimensional Neural Network](./Labs/7.3xor_v2.ipynb)

## 7.4 Multi-Class Neural Networks

- [Video - 7.4 Multi-Class Neural Networks](https://www.coursera.org/learn/deep-neural-networks-with-pytorch/lecture/FxuLM/7-4-multi-class-neural-networks)

- [Lab - Multi-Class Neural Networks with MNIST](./Labs/7.4one_layer_neural_network_MNIST.ipynb)

## 7.5 Backpropagation

- [Video - 7.5 Backpropagation](https://www.coursera.org/learn/deep-neural-networks-with-pytorch/lecture/yCwq4/7-5-backpropagation)

## 7.6 Activation Functions

- [Video - 7.5 Activation Functions](https://www.coursera.org/learn/deep-neural-networks-with-pytorch/lecture/98zKo/7-5-activation-functions)

- [Lab - Activation Functions](./Labs/7.5.1activationfuction_v2.ipynb)

- [Lab - Neural Network with Different Activation Functions](./Labs/7.5.2mist1layer_v2.ipynb)